---
title: Quick Start
description: Add persistent memory to any AI model in 5 minutes.
---

**Your AI remembers everything.** Change one URL, get persistent memory across all your AI conversations.

```python
# Before: Stateless AI with amnesia
client = OpenAI(api_key="sk-xxx")

# After: AI with perfect memory
client = OpenAI(api_key="mk_xxx", base_url="https://api.memoryrouter.ai/v1")
```

---

## Quick Start (5 minutes)

### Step 1: Get Your Memory Key

1. Go to [app.memoryrouter.ai](https://app.memoryrouter.ai)
2. Sign in with Google
3. Add your OpenAI/Anthropic API key(s) in Settings
4. Copy your Memory Key (`mk_xxxxxxxxxxxxxxxx`)

### Step 2: Swap One Line

**Python (OpenAI SDK):**
```python
from openai import OpenAI

client = OpenAI(
    api_key="mk_xxxxxxxxxxxxxxxx",  # Your Memory Key
    base_url="https://api.memoryrouter.ai/v1"
)

response = client.chat.completions.create(
    model="openai/gpt-4o",
    messages=[{"role": "user", "content": "My name is Alice"}]
)
print(response.choices[0].message.content)
```

**JavaScript:**
```javascript
import OpenAI from 'openai';

const client = new OpenAI({
    apiKey: 'mk_xxxxxxxxxxxxxxxx',
    baseURL: 'https://api.memoryrouter.ai/v1'
});

const response = await client.chat.completions.create({
    model: 'openai/gpt-4o',
    messages: [{ role: 'user', content: 'My name is Alice' }]
});
```

**curl:**
```bash
curl -X POST https://api.memoryrouter.ai/v1/chat/completions \
  -H "Authorization: Bearer mk_xxxxxxxxxxxxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o",
    "messages": [{"role": "user", "content": "My name is Alice"}]
  }'
```

### Step 3: Watch the Memory Work

```python
# First request - introduce yourself
client.chat.completions.create(
    model="openai/gpt-4o",
    messages=[{"role": "user", "content": "My name is Alice and I love hiking"}]
)

# Later (even days later) - the AI remembers
response = client.chat.completions.create(
    model="openai/gpt-4o",
    messages=[{"role": "user", "content": "What are my hobbies?"}]
)
# Response: "Based on our previous conversation, you mentioned you love hiking!"
```

---

## How It Works

MemoryRouter sits between your app and your AI provider:
1. **Queries** your semantic-temporal memory store
2. **Injects** relevant context into your prompt
3. **Forwards** to your chosen AI provider
4. **Stores** new memories automatically
5. **Returns** the response â€” standard format, zero changes to your code

---

## Supported Providers

Use any model from these providers â€” just prefix the model name:

| Provider | Example Models | Prefix |
|----------|---------------|--------|
| OpenAI | gpt-4o, gpt-4o-mini, o1, o3-mini | `openai/` |
| Anthropic | claude-3-5-sonnet, claude-3-opus | `anthropic/` |
| Google | gemini-1.5-pro, gemini-2.0-flash | `google/` |
| OpenRouter | any model on openrouter.ai | `openrouter/` |
| xAI | grok-beta, grok-2 | `xai/` |
| DeepSeek | deepseek-chat, deepseek-reasoner | `deepseek/` |
| Mistral | mistral-large, mistral-small | `mistral/` |
| Cerebras | llama-3.1-70b, llama-3.1-8b | `cerebras/` |
| Azure OpenAI | your deployed models | `azure/` |
| Ollama | local models | `ollama/` |

**OpenRouter** gives you access to 200+ models through a single API key â€” perfect for trying different models with the same memory.

---

## Links

- **Dashboard**: [app.memoryrouter.ai](https://app.memoryrouter.ai)
- **API**: `https://api.memoryrouter.ai/v1`

---

*MemoryRouter â€” Same memory, any model.* ðŸ§ 
