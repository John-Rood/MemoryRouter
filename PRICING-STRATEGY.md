# MemoryRouter Pricing Strategy

## The Claim

> **Store once, recall forever.**
> 
> Instead of sending 50K tokens of context every call, send 5K of recalled memory.
> Same quality, 90% less spend.

## The Math

> **$1 on memory saves $10 on inference.**

That's it. That's the value prop.

---

## Pricing

| Tier | Price |
|------|-------|
| **Free** | 50M tokens |
| **Paid** | $0.50 per 1M tokens stored |
| **Enterprise** | Custom (volume + SLA + compliance) |

No tiers. No complexity. One number.

---

## The Funnel

```
Bold claim → Free trial → They prove it → They pay → We profit
```

1. **Bold claim** — "$0.50 saves $2-3" plastered everywhere
2. **Instant start** — 50M tokens free, one API call, no friction
3. **They prove it** — Dashboard shows tokens stored, inference saved
4. **They pay** — Hit the limit, card down, keep going
5. **We profit** — Their growth is our growth

---

## Why It Works

### For Developers
- Familiar units (tokens/million — same as OpenAI/Anthropic)
- Obvious ROI (spend $0.50, save $2-3)
- No risk (free tier proves value first)
- Predictable costs (one price, scales linearly)

### For Us
- **80%+ gross margins** ($0.50/M revenue, ~$0.05-0.10 cost)
- **CAC of ~$1-2** (free tier compute = marketing spend)
- **LTV of $500+** (sticky data, low churn)
- **No sales team** (product sells itself)

---

## Lock-In

Once they have 3-6 months of memories:
- Their AI depends on this context
- Their users expect to be remembered
- Switching = rebuilding + worse product

We don't need contracts. The data locks them in.

---

## Enterprise

Starting at $5k/mo. They pay for:
- 99.9% uptime SLA
- SOC 2 / HIPAA compliance
- Dedicated support
- Custom retention policies
- Volume discounts

They're not paying for cheaper tokens. They're paying for guarantees.

---

## Competitive Position

| They Say | We Say |
|----------|--------|
| OpenAI/Anthropic: "$3-15/M tokens" | "We make them cheaper to use" |
| Pinecone: "Vector storage" | "We're memory, not infrastructure" |
| DIY: "Just build it" | "We save you 6 weeks and $2-3 per million" |

---

## The One-Liners

**Homepage:** "$1 on memory saves $10 on inference."

**Developers:** "50M tokens free. Watch your inference costs drop."

**Enterprise:** "Cut AI costs 40-60% with memory that scales."

**Investors:** "We're the efficiency layer every AI app needs."

---

## What We Need to Prove

1. **Benchmark** — "App X reduced inference costs by Y%"
2. **Speed** — "Add memory in 5 minutes"
3. **Quality** — "Response quality improved by Z%"

Publish these. Let results speak.

---

## What NOT to Do

- ❌ Complex tier structures
- ❌ Per-feature pricing
- ❌ Seat-based pricing
- ❌ Annual commitments required
- ❌ "Contact sales" for basic info
- ❌ Comparing to vector databases

---

## Summary

| | |
|---|---|
| **Free** | 50M tokens |
| **Paid** | $0.50 / 1M tokens |
| **Enterprise** | Custom |
| **Pitch** | $0.50 saves $2-3 |

Simple. Obvious. Prints money.

---

*January 2026*
