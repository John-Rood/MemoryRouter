<!--
  MemoryRouter Latency Test
  =========================
  
  PURPOSE: Measure MemoryRouter latency overhead before launch
  
  HOW TO USE:
  1. Open this file in any browser
  2. Enter your MemoryRouter API Key (mk_xxx)
  3. Enter model (e.g., openai/gpt-4o)
  4. Chat and watch latency metrics
  
  LATENCY METRICS:
  - TTFB (Time to First Byte): When streaming starts â€” measures MemoryRouter overhead
  - Total Time: Full request duration
  - Min/Max/Avg: Tracked across session
  
  The key metric is TTFB â€” this shows how much latency MemoryRouter adds
  before the AI provider starts responding.
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MemoryRouter Latency Test</title>
  <!-- Marked.js for markdown rendering -->
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    
    :root {
      --bg: #0a0a0f;
      --bg-secondary: #13131a;
      --bg-tertiary: #1a1a24;
      --text: #e4e4e7;
      --text-muted: #71717a;
      --accent: #22c55e;
      --accent-bright: #4ade80;
      --accent-dim: rgba(34, 197, 94, 0.15);
      --border: #27272a;
      --error: #ef4444;
      --warning: #f59e0b;
      --user-bg: #1e3a5f;
      --assistant-bg: #1a1a24;
    }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: var(--bg);
      color: var(--text);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }
    
    /* Header */
    header {
      background: var(--bg-secondary);
      border-bottom: 1px solid var(--border);
      padding: 16px 24px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      flex-wrap: wrap;
      gap: 16px;
    }
    
    .logo {
      display: flex;
      align-items: center;
      gap: 10px;
    }
    
    .logo h1 {
      font-size: 20px;
      font-weight: 600;
      color: var(--text);
    }
    
    .logo span {
      color: var(--accent);
    }
    
    .logo .subtitle {
      font-size: 12px;
      color: var(--text-muted);
      font-weight: 400;
      margin-left: 8px;
      padding-left: 8px;
      border-left: 1px solid var(--border);
    }
    
    /* Config Panel */
    .config {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }
    
    .config-field {
      display: flex;
      flex-direction: column;
      gap: 4px;
    }
    
    .config-field label {
      font-size: 11px;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    
    .config-field input {
      background: var(--bg-tertiary);
      border: 1px solid var(--border);
      border-radius: 6px;
      padding: 8px 12px;
      color: var(--text);
      font-size: 14px;
      outline: none;
      transition: border-color 0.2s;
    }
    
    .config-field input:focus {
      border-color: var(--accent);
    }
    
    .config-field input::placeholder {
      color: var(--text-muted);
    }
    
    #apiKey {
      width: 220px;
      font-family: monospace;
    }
    
    #model {
      width: 200px;
    }
    
    #benchmarkBtn {
      background: var(--bg-tertiary);
      border: 1px solid var(--accent);
      color: var(--accent);
      padding: 10px 20px;
      border-radius: 8px;
      font-weight: 600;
      font-size: 13px;
      cursor: pointer;
      transition: all 0.2s;
      white-space: nowrap;
      align-self: flex-end;
      height: 42px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    #benchmarkBtn:hover {
      background: var(--accent);
      color: var(--bg);
    }
    
    #benchmarkBtn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    
    @media (max-width: 600px) {
      .config {
        flex-direction: column;
        align-items: stretch;
      }
      #benchmarkBtn {
        width: 100%;
        margin-top: 8px;
      }
    }
    
    /* HERO: Latency Stats Panel */
    .latency-panel {
      background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%);
      border-bottom: 1px solid var(--border);
      padding: 20px 24px;
    }
    
    .latency-header {
      display: flex;
      align-items: center;
      gap: 8px;
      margin-bottom: 16px;
    }
    
    .latency-header h2 {
      font-size: 14px;
      font-weight: 600;
      color: var(--text);
      text-transform: uppercase;
      letter-spacing: 1px;
    }
    
    .latency-header .badge {
      background: var(--accent-dim);
      color: var(--accent);
      font-size: 11px;
      padding: 3px 8px;
      border-radius: 4px;
      font-weight: 500;
    }
    
    .latency-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
      gap: 16px;
    }
    
    .latency-stat {
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: 16px;
      display: flex;
      flex-direction: column;
      gap: 6px;
    }
    
    .latency-stat.hero {
      border-color: var(--accent);
      background: linear-gradient(135deg, var(--accent-dim) 0%, var(--bg) 100%);
    }
    
    .latency-stat .label {
      font-size: 11px;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.5px;
      display: flex;
      align-items: center;
      gap: 6px;
    }
    
    .latency-stat .label .hint {
      font-size: 10px;
      color: var(--text-muted);
      opacity: 0.7;
      text-transform: none;
      letter-spacing: 0;
    }
    
    .latency-stat .value {
      font-size: 28px;
      font-weight: 700;
      font-variant-numeric: tabular-nums;
      color: var(--accent-bright);
      line-height: 1;
    }
    
    .latency-stat.hero .value {
      font-size: 36px;
    }
    
    .latency-stat .unit {
      font-size: 14px;
      font-weight: 400;
      color: var(--accent);
      margin-left: 2px;
    }
    
    .latency-stat .secondary {
      font-size: 12px;
      color: var(--text-muted);
      font-variant-numeric: tabular-nums;
    }
    
    .latency-stat.warning .value {
      color: var(--warning);
    }
    
    .latency-stat.error .value {
      color: var(--error);
    }
    
    /* Request counter row */
    .request-stats {
      display: flex;
      gap: 24px;
      margin-top: 16px;
      padding-top: 16px;
      border-top: 1px solid var(--border);
    }
    
    .request-stat {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 13px;
    }
    
    .request-stat .label {
      color: var(--text-muted);
    }
    
    .request-stat .value {
      font-weight: 600;
      font-variant-numeric: tabular-nums;
      color: var(--text);
    }
    
    .request-stat.success .value {
      color: var(--accent);
    }
    
    .request-stat.error .value {
      color: var(--error);
    }
    
    /* Chat Container */
    .chat-container {
      flex: 1;
      display: flex;
      flex-direction: column;
      max-width: 900px;
      width: 100%;
      margin: 0 auto;
      padding: 24px;
    }
    
    /* Messages */
    .messages {
      flex: 1;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 16px;
      padding-bottom: 24px;
    }
    
    .message {
      display: flex;
      flex-direction: column;
      gap: 8px;
      max-width: 85%;
    }
    
    .message.user {
      align-self: flex-end;
    }
    
    .message.assistant {
      align-self: flex-start;
    }
    
    .message-header {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 12px;
      color: var(--text-muted);
    }
    
    .message.user .message-header {
      justify-content: flex-end;
    }
    
    .message-role {
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    
    .message-latency {
      display: flex;
      align-items: center;
      gap: 6px;
      font-variant-numeric: tabular-nums;
    }
    
    .message-latency .ttfb {
      color: var(--accent);
      font-weight: 600;
    }
    
    .message-latency .total {
      color: var(--text-muted);
    }
    
    .message-content {
      padding: 14px 18px;
      border-radius: 12px;
      font-size: 15px;
      line-height: 1.5;
      white-space: pre-wrap;
      word-break: break-word;
    }
    
    .message.user .message-content {
      background: var(--user-bg);
      border-bottom-right-radius: 4px;
    }
    
    .message.assistant .message-content {
      background: var(--assistant-bg);
      border: 1px solid var(--border);
      border-bottom-left-radius: 4px;
    }
    
    .message.error .message-content {
      background: rgba(239, 68, 68, 0.1);
      border: 1px solid var(--error);
      color: var(--error);
    }
    
    /* Markdown styles */
    .message-content p { margin-bottom: 12px; }
    .message-content p:last-child { margin-bottom: 0; }
    .message-content h1, .message-content h2, .message-content h3 {
      margin: 16px 0 8px;
      color: var(--accent);
    }
    .message-content h1 { font-size: 1.4em; }
    .message-content h2 { font-size: 1.2em; }
    .message-content h3 { font-size: 1.1em; }
    .message-content code {
      background: var(--bg-tertiary);
      padding: 2px 6px;
      border-radius: 4px;
      font-family: 'SF Mono', Monaco, monospace;
      font-size: 0.9em;
    }
    .message-content pre {
      background: var(--bg-tertiary);
      border: 1px solid var(--border);
      border-radius: 6px;
      padding: 12px;
      overflow-x: auto;
      margin: 12px 0;
      white-space: pre;
    }
    .message-content pre code {
      background: none;
      padding: 0;
    }
    .message-content ul, .message-content ol {
      margin: 12px 0;
      padding-left: 24px;
    }
    .message-content li { margin: 4px 0; }
    .message-content blockquote {
      border-left: 3px solid var(--accent);
      padding-left: 12px;
      margin: 12px 0;
      color: var(--text-muted);
    }
    .message-content table {
      width: 100%;
      border-collapse: collapse;
      margin: 12px 0;
    }
    .message-content th, .message-content td {
      border: 1px solid var(--border);
      padding: 8px 12px;
      text-align: left;
    }
    .message-content th {
      background: var(--bg-tertiary);
      font-weight: 600;
    }
    .message-content a {
      color: var(--accent-bright);
      text-decoration: none;
    }
    .message-content a:hover { text-decoration: underline; }
    .message-content strong { color: var(--accent); }
    
    /* Streaming indicator */
    .streaming-indicator {
      display: inline-block;
      width: 8px;
      height: 16px;
      background: var(--accent);
      animation: blink 0.7s infinite;
      margin-left: 2px;
      vertical-align: text-bottom;
    }
    
    @keyframes blink {
      0%, 50% { opacity: 1; }
      51%, 100% { opacity: 0; }
    }
    
    /* Input Area */
    .input-area {
      display: flex;
      gap: 12px;
      background: var(--bg-secondary);
      padding: 16px;
      border-radius: 12px;
      border: 1px solid var(--border);
    }
    
    #messageInput {
      flex: 1;
      background: var(--bg-tertiary);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 12px 16px;
      color: var(--text);
      font-size: 15px;
      outline: none;
      resize: none;
      min-height: 48px;
      max-height: 150px;
      font-family: inherit;
    }
    
    #messageInput:focus {
      border-color: var(--accent);
    }
    
    #messageInput::placeholder {
      color: var(--text-muted);
    }
    
    #sendBtn {
      background: var(--accent);
      color: #000;
      border: none;
      border-radius: 8px;
      padding: 12px 24px;
      font-size: 15px;
      font-weight: 600;
      cursor: pointer;
      transition: opacity 0.2s;
      display: flex;
      align-items: center;
      gap: 8px;
    }
    
    #sendBtn:hover {
      opacity: 0.9;
    }
    
    #sendBtn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    
    /* Empty state */
    .empty-state {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      color: var(--text-muted);
      gap: 16px;
      padding: 48px;
      text-align: center;
    }
    
    .empty-state svg {
      width: 64px;
      height: 64px;
      opacity: 0.5;
    }
    
    .empty-state h2 {
      font-size: 18px;
      font-weight: 500;
      color: var(--text);
    }
    
    .empty-state p {
      font-size: 14px;
      max-width: 400px;
    }
    
    .empty-state code {
      background: var(--bg-tertiary);
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 13px;
    }
    
    /* Context indicator */
    .context-info {
      font-size: 12px;
      color: var(--text-muted);
      text-align: center;
      padding: 8px;
    }
    
    .context-info span {
      color: var(--accent);
    }
    
    /* Responsive */
    @media (max-width: 768px) {
      header {
        flex-direction: column;
        align-items: flex-start;
      }
      
      .config {
        width: 100%;
      }
      
      .config-field input {
        width: 100% !important;
      }
      
      .latency-grid {
        grid-template-columns: repeat(2, 1fr);
      }
      
      .latency-stat .value {
        font-size: 22px;
      }
      
      .latency-stat.hero .value {
        font-size: 28px;
      }
    }
  </style>
</head>
<body>
  <header>
    <div class="logo">
      <h1>Memory<span>Router</span></h1>
      <span class="subtitle">Latency Test</span>
    </div>
    
    <div class="config">
      <div class="config-field">
        <label>Environment</label>
        <select id="environment">
          <option value="production">ğŸŸ¢ Production</option>
          <option value="staging">ğŸŸ¡ Staging</option>
        </select>
      </div>
      <div class="config-field">
        <label>API Key</label>
        <input type="password" id="apiKey" placeholder="mk_xxxxxxxx">
      </div>
      <div class="config-field">
        <label>Model</label>
        <input type="text" id="model" placeholder="openai/gpt-4o">
      </div>
      <button id="benchmarkBtn">
        ğŸš€ Run Benchmark
      </button>
    </div>
  </header>
  
  <!-- HERO: Latency Metrics -->
  <div class="latency-panel">
    <div class="latency-header">
      <h2>âš¡ Latency Metrics</h2>
      <span class="badge">STREAMING</span>
    </div>
    
    <div class="latency-grid">
      <div class="latency-stat hero" id="mrProcessingStat">
        <span class="label">
          MR Processing
          <span class="hint">(Auth + Vectors + Inject)</span>
        </span>
        <span class="value"><span id="lastMRProcessing">â€”</span><span class="unit">ms</span></span>
        <span class="secondary">Our overhead</span>
      </div>
      
      <div class="latency-stat" id="providerStat">
        <span class="label">
          AI Provider
          <span class="hint">(OpenAI/Anthropic)</span>
        </span>
        <span class="value"><span id="lastProvider">â€”</span><span class="unit">ms</span></span>
        <span class="secondary">Time waiting on AI</span>
      </div>
      
      <div class="latency-stat">
        <span class="label">
          Total Time
          <span class="hint">(End to End)</span>
        </span>
        <span class="value"><span id="lastTotal">â€”</span><span class="unit">ms</span></span>
        <span class="secondary">Full request</span>
      </div>
      
      <div class="latency-stat">
        <span class="label">Avg MR</span>
        <span class="value"><span id="avgMRProcessing">â€”</span><span class="unit">ms</span></span>
      </div>
      
      <div class="latency-stat">
        <span class="label">Avg Provider</span>
        <span class="value"><span id="avgProvider">â€”</span><span class="unit">ms</span></span>
      </div>
      
      <div class="latency-stat">
        <span class="label">Avg Total</span>
        <span class="value"><span id="avgTotal">â€”</span><span class="unit">ms</span></span>
      </div>
    </div>
    
    <div class="request-stats">
      <div class="request-stat">
        <span class="label">Requests:</span>
        <span class="value" id="totalRequests">0</span>
      </div>
      <div class="request-stat success">
        <span class="label">Success:</span>
        <span class="value" id="successCount">0</span>
      </div>
      <div class="request-stat error">
        <span class="label">Failed:</span>
        <span class="value" id="failCount">0</span>
      </div>
    </div>
  </div>
  
  <div class="chat-container">
    <div class="messages" id="messages">
      <div class="empty-state" id="emptyState">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
          <path d="M13 10V3L4 14h7v7l9-11h-7z" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
        <h2>Test MemoryRouter Latency</h2>
        <p>
          Measures <code>TTFB</code> (Time to First Byte) â€” the latency MemoryRouter adds before streaming starts.
          <br><br>
          Last 3 messages sent as context. Uses streaming to measure real latency.
        </p>
      </div>
    </div>
    
    <div class="context-info" id="contextInfo" style="display: none;">
      Sending <span id="contextCount">0</span> messages as context
    </div>
    
    <div class="input-area">
      <textarea id="messageInput" placeholder="Type a message..." rows="1"></textarea>
      <button id="sendBtn">
        Send
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M22 2L11 13M22 2l-7 20-4-9-9-4 20-7z" stroke-linecap="round" stroke-linejoin="round"/>
        </svg>
      </button>
    </div>
  </div>

  <script>
    // ========================
    // State
    // ========================
    const state = {
      messages: [],
      mrProcessingTimes: [],  // MR processing time (auth + vectors + inject)
      providerTimes: [],      // AI provider response time
      totalTimes: [],         // Total request time (ms)
      successCount: 0,
      failCount: 0,
      isLoading: false
    };

    // ========================
    // Environment URLs
    // ========================
    const ENVIRONMENTS = {
      production: 'https://api.memoryrouter.ai',
      staging: 'https://memoryrouter-staging.roodbiz.workers.dev',
    };
    
    function getApiBase() {
      const env = document.getElementById('environment')?.value || 'production';
      return ENVIRONMENTS[env];
    }

    // ========================
    // DOM Elements
    // ========================
    const environmentInput = document.getElementById('environment');
    const apiKeyInput = document.getElementById('apiKey');
    const modelInput = document.getElementById('model');
    const messagesContainer = document.getElementById('messages');
    const messageInput = document.getElementById('messageInput');
    const sendBtn = document.getElementById('sendBtn');
    const emptyState = document.getElementById('emptyState');
    const contextInfo = document.getElementById('contextInfo');
    const contextCount = document.getElementById('contextCount');
    
    // Latency elements - new breakdown
    const lastMRProcessingEl = document.getElementById('lastMRProcessing');
    const lastProviderEl = document.getElementById('lastProvider');
    const lastTotalEl = document.getElementById('lastTotal');
    const avgMRProcessingEl = document.getElementById('avgMRProcessing');
    const avgProviderEl = document.getElementById('avgProvider');
    const avgTotalEl = document.getElementById('avgTotal');
    const mrProcessingStatEl = document.getElementById('mrProcessingStat');
    const providerStatEl = document.getElementById('providerStat');
    
    // Request stats
    const totalRequestsEl = document.getElementById('totalRequests');
    const successCountEl = document.getElementById('successCount');
    const failCountEl = document.getElementById('failCount');

    // ========================
    // LocalStorage
    // ========================
    function loadConfig() {
      const savedEnv = localStorage.getItem('memoryrouter_env');
      const savedKey = localStorage.getItem('memoryrouter_apikey');
      const savedModel = localStorage.getItem('memoryrouter_model');
      
      if (savedEnv && environmentInput) environmentInput.value = savedEnv;
      if (savedKey) apiKeyInput.value = savedKey;
      if (savedModel) modelInput.value = savedModel;
      else modelInput.value = 'openai/gpt-4o';
    }

    function saveConfig() {
      localStorage.setItem('memoryrouter_env', environmentInput?.value || 'production');
      localStorage.setItem('memoryrouter_apikey', apiKeyInput.value);
      localStorage.setItem('memoryrouter_model', modelInput.value);
    }

    // ========================
    // Latency Stats
    // ========================
    function updateLatencyStats(mrProcessing, providerTime, total, success = true) {
      if (mrProcessing !== null && providerTime !== null) {
        state.mrProcessingTimes.push(mrProcessing);
        state.providerTimes.push(providerTime);
        state.totalTimes.push(total);
        
        // Last values
        lastMRProcessingEl.textContent = Math.round(mrProcessing);
        lastProviderEl.textContent = Math.round(providerTime);
        lastTotalEl.textContent = Math.round(total);
        
        // Color code MR Processing (our overhead)
        mrProcessingStatEl.classList.remove('warning', 'error');
        if (mrProcessing > 500) mrProcessingStatEl.classList.add('error');
        else if (mrProcessing > 200) mrProcessingStatEl.classList.add('warning');
        
        // Averages
        const avgMR = state.mrProcessingTimes.reduce((a, b) => a + b, 0) / state.mrProcessingTimes.length;
        const avgProv = state.providerTimes.reduce((a, b) => a + b, 0) / state.providerTimes.length;
        const avgTotal = state.totalTimes.reduce((a, b) => a + b, 0) / state.totalTimes.length;
        
        avgMRProcessingEl.textContent = Math.round(avgMR);
        avgProviderEl.textContent = Math.round(avgProv);
        avgTotalEl.textContent = Math.round(avgTotal);
      }
      
      // Update counts
      if (success) state.successCount++;
      else state.failCount++;
      
      totalRequestsEl.textContent = state.successCount + state.failCount;
      successCountEl.textContent = state.successCount;
      failCountEl.textContent = state.failCount;
    }

    function formatTime(ms) {
      if (ms < 1000) return Math.round(ms);
      return (ms / 1000).toFixed(1) + 'k';
    }

    function formatTimeDisplay(ms) {
      if (ms < 1000) return Math.round(ms) + 'ms';
      return (ms / 1000).toFixed(2) + 's';
    }

    // ========================
    // Context Management
    // ========================
    function getContextMessages() {
      return state.messages.slice(-3).map(m => ({
        role: m.role,
        content: m.content
      }));
    }

    function updateContextInfo() {
      const count = Math.min(state.messages.length, 3);
      if (count > 0) {
        contextInfo.style.display = 'block';
        contextCount.textContent = count;
      } else {
        contextInfo.style.display = 'none';
      }
    }

    // ========================
    // Chat UI
    // ========================
    function addUserMessage(content) {
      if (emptyState) emptyState.style.display = 'none';
      
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message user';
      messageDiv.innerHTML = `
        <div class="message-header">
          <span class="message-role">You</span>
        </div>
        <div class="message-content">${escapeHtml(content)}</div>
      `;
      
      messagesContainer.appendChild(messageDiv);
      messagesContainer.scrollTop = messagesContainer.scrollHeight;
      
      state.messages.push({ role: 'user', content });
      updateContextInfo();
    }

    function createAssistantMessage() {
      if (emptyState) emptyState.style.display = 'none';
      
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message assistant';
      messageDiv.innerHTML = `
        <div class="message-header">
          <span class="message-role">Assistant</span>
          <div class="message-latency">
            <span class="mr-time" id="currentMR">...</span>
            <span class="total" id="currentTotal"></span>
          </div>
        </div>
        <div class="message-content"><span class="streaming-indicator"></span></div>
      `;
      
      messagesContainer.appendChild(messageDiv);
      messagesContainer.scrollTop = messagesContainer.scrollHeight;
      
      return messageDiv;
    }

    function updateAssistantMessage(messageDiv, content, mrTime = null, total = null, isError = false) {
      const contentEl = messageDiv.querySelector('.message-content');
      const mrEl = messageDiv.querySelector('#currentMR');
      const totalEl = messageDiv.querySelector('#currentTotal');
      
      if (isError) {
        messageDiv.classList.add('error');
        contentEl.innerHTML = escapeHtml(content);
      } else {
        // Use markdown for streaming content
        contentEl.innerHTML = marked.parse(content) + '<span class="streaming-indicator"></span>';
      }
      
      if (mrTime !== null) {
        mrEl.textContent = `MR: ${Math.round(mrTime)}ms`;
      }
      
      if (total !== null) {
        totalEl.textContent = ` Â· Total: ${formatTimeDisplay(total)}`;
      }
      
      messagesContainer.scrollTop = messagesContainer.scrollHeight;
    }

    function finalizeAssistantMessage(messageDiv, content, mrTime, total) {
      const contentEl = messageDiv.querySelector('.message-content');
      const mrEl = messageDiv.querySelector('#currentMR');
      const totalEl = messageDiv.querySelector('#currentTotal');
      
      // Use markdown for final content
      contentEl.innerHTML = marked.parse(content);
      mrEl.textContent = `MR: ${Math.round(mrTime)}ms`;
      totalEl.textContent = ` Â· Total: ${formatTimeDisplay(total)}`;
      
      state.messages.push({ role: 'assistant', content });
      updateContextInfo();
    }

    function escapeHtml(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }

    // ========================
    // Streaming API Call
    // ========================
    async function sendMessage() {
      const apiKey = apiKeyInput.value.trim();
      const model = modelInput.value.trim();
      const userMessage = messageInput.value.trim();
      
      if (!apiKey) {
        alert('Please enter your MemoryRouter API key');
        apiKeyInput.focus();
        return;
      }
      
      if (!model) {
        alert('Please enter a model (e.g., openai/gpt-4o)');
        modelInput.focus();
        return;
      }
      
      if (!userMessage) return;
      
      saveConfig();
      
      messageInput.value = '';
      messageInput.style.height = 'auto';
      state.isLoading = true;
      sendBtn.disabled = true;
      
      addUserMessage(userMessage);
      
      // Build context (last 3 messages BEFORE new message)
      const contextMessages = getContextMessages();
      const messages = [
        ...contextMessages.slice(0, -1),
        { role: 'user', content: userMessage }
      ];
      
      const assistantDiv = createAssistantMessage();
      
      // Timing
      const startTime = performance.now();
      let clientTTFB = null;
      let mrProcessingMs = null;
      let providerMs = null;
      let fullResponse = '';
      
      try {
        const response = await fetch(`${getApiBase()}/v1/chat/completions`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: model,
            messages: messages,
            stream: true
          })
        });
        
        // Read latency headers from backend
        mrProcessingMs = parseInt(response.headers.get('X-MR-Processing-Ms') || '0');
        providerMs = parseInt(response.headers.get('X-Provider-Response-Ms') || '0');
        
        if (!response.ok) {
          const endTime = performance.now();
          const errorData = await response.json().catch(() => ({ error: { message: response.statusText } }));
          const errorMsg = errorData.error?.message || errorData.error?.provider_error?.error?.message || 'Request failed';
          updateAssistantMessage(assistantDiv, `Error: ${errorMsg}`, null, endTime - startTime, true);
          updateLatencyStats(null, null, null, false);
          return;
        }
        
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        
        while (true) {
          const { done, value } = await reader.read();
          
          if (done) break;
          
          // Record client-side TTFB on first chunk
          if (clientTTFB === null) {
            clientTTFB = performance.now() - startTime;
            updateAssistantMessage(assistantDiv, '', clientTTFB);
          }
          
          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');
          
          for (const line of lines) {
            if (line.startsWith('data: ') && !line.includes('[DONE]')) {
              try {
                const data = JSON.parse(line.slice(6));
                const content = data.choices?.[0]?.delta?.content;
                const anthropicContent = data.delta?.text;
                
                if (content) fullResponse += content;
                if (anthropicContent) fullResponse += anthropicContent;
                
                if (content || anthropicContent) {
                  updateAssistantMessage(assistantDiv, fullResponse, clientTTFB);
                }
              } catch {
                // Ignore parse errors
              }
            }
          }
        }
        
        const endTime = performance.now();
        const totalTime = endTime - startTime;
        
        // Log detailed latency breakdown to console
        console.log(`%c[MemoryRouter Latency Breakdown]`, 'color: #22c55e; font-weight: bold', {
          requestNumber: state.successCount + state.failCount + 1,
          mrProcessing: `${mrProcessingMs}ms`,
          providerTime: `${providerMs}ms`,
          clientTTFB: `${clientTTFB?.toFixed(2)}ms`,
          totalTime: `${totalTime.toFixed(2)}ms`,
          timestamp: new Date().toISOString()
        });
        
        finalizeAssistantMessage(assistantDiv, fullResponse, mrProcessingMs, totalTime);
        updateLatencyStats(mrProcessingMs, providerMs, totalTime, true);
        
      } catch (error) {
        const endTime = performance.now();
        const totalTime = endTime - startTime;
        
        // Log error latency to console
        console.log(`%c[MemoryRouter ERROR]`, 'color: #ef4444; font-weight: bold', {
          error: error.message,
          total: `${totalTime.toFixed(2)}ms`,
          timestamp: new Date().toISOString()
        });
        
        updateAssistantMessage(assistantDiv, `Network error: ${error.message}`, null, totalTime, true);
        updateLatencyStats(null, null, null, false);
      } finally {
        state.isLoading = false;
        sendBtn.disabled = false;
        messageInput.focus();
      }
    }

    // ========================
    // Event Listeners
    // ========================
    sendBtn.addEventListener('click', sendMessage);
    
    messageInput.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        if (!state.isLoading) sendMessage();
      }
    });
    
    messageInput.addEventListener('input', () => {
      messageInput.style.height = 'auto';
      messageInput.style.height = Math.min(messageInput.scrollHeight, 150) + 'px';
    });
    
    if (environmentInput) {
      environmentInput.addEventListener('change', saveConfig);
    }
    apiKeyInput.addEventListener('change', saveConfig);
    modelInput.addEventListener('change', saveConfig);
    
    // Benchmark button
    const benchmarkBtn = document.getElementById('benchmarkBtn');
    const testPrompts = [
      "What is 2+2?",
      "Say hello in 3 words.",
      "What color is the sky?",
      "Count to 5.",
      "Name a fruit."
    ];
    
    async function runBenchmark() {
      const apiKey = apiKeyInput.value.trim();
      const model = modelInput.value.trim();
      
      if (!apiKey) {
        alert('Please enter your MemoryRouter API key');
        apiKeyInput.focus();
        return;
      }
      
      if (!model) {
        alert('Please enter a model (e.g., openai/gpt-4o)');
        modelInput.focus();
        return;
      }
      
      saveConfig();
      benchmarkBtn.disabled = true;
      benchmarkBtn.textContent = 'â³ Running...';
      
      for (let i = 0; i < testPrompts.length; i++) {
        benchmarkBtn.textContent = `â³ Running ${i + 1}/${testPrompts.length}...`;
        messageInput.value = testPrompts[i];
        await sendMessage();
        // Small delay between requests
        await new Promise(r => setTimeout(r, 500));
      }
      
      benchmarkBtn.disabled = false;
      benchmarkBtn.textContent = 'ğŸš€ Run Benchmark (5 requests)';
      
      // Show summary in console
      dumpLatencyStats();
      const avgMR = document.getElementById('avgMRProcessing').textContent;
      const avgProv = document.getElementById('avgProvider').textContent;
      alert(`Benchmark complete!\n\nAvg MR Processing: ${avgMR}ms\nAvg AI Provider: ${avgProv}ms`);
    }
    
    benchmarkBtn.addEventListener('click', runBenchmark);
    
    // Global function to dump latency stats - call from console: dumpLatencyStats()
    window.dumpLatencyStats = function() {
      if (state.mrProcessingTimes.length === 0) {
        console.log('%c[MemoryRouter] No requests yet', 'color: #f59e0b');
        return;
      }
      
      const avgMR = state.mrProcessingTimes.reduce((a, b) => a + b, 0) / state.mrProcessingTimes.length;
      const minMR = Math.min(...state.mrProcessingTimes);
      const maxMR = Math.max(...state.mrProcessingTimes);
      
      const avgProv = state.providerTimes.reduce((a, b) => a + b, 0) / state.providerTimes.length;
      const minProv = Math.min(...state.providerTimes);
      const maxProv = Math.max(...state.providerTimes);
      
      const avgTotal = state.totalTimes.reduce((a, b) => a + b, 0) / state.totalTimes.length;
      
      console.log('%câ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—', 'color: #22c55e');
      console.log('%câ•‘   MEMORYROUTER LATENCY BREAKDOWN               â•‘', 'color: #22c55e; font-weight: bold');
      console.log('%câ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£', 'color: #22c55e');
      console.log(`%câ•‘ Total Requests: ${state.successCount + state.failCount}`, 'color: #22c55e');
      console.log(`%câ•‘ Successful: ${state.successCount} | Failed: ${state.failCount}`, 'color: #22c55e');
      console.log('%câ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£', 'color: #22c55e');
      console.log(`%câ•‘ MR PROCESSING (Our Overhead):`, 'color: #22c55e; font-weight: bold');
      console.log(`%câ•‘   Average: ${avgMR.toFixed(2)}ms`, 'color: #4ade80');
      console.log(`%câ•‘   Min: ${minMR.toFixed(2)}ms | Max: ${maxMR.toFixed(2)}ms`, 'color: #4ade80');
      console.log('%câ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£', 'color: #22c55e');
      console.log(`%câ•‘ AI PROVIDER (OpenAI/Anthropic):`, 'color: #22c55e; font-weight: bold');
      console.log(`%câ•‘   Average: ${avgProv.toFixed(2)}ms`, 'color: #4ade80');
      console.log(`%câ•‘   Min: ${minProv.toFixed(2)}ms | Max: ${maxProv.toFixed(2)}ms`, 'color: #4ade80');
      console.log('%câ• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£', 'color: #22c55e');
      console.log(`%câ•‘ TOTAL (End to End):`, 'color: #22c55e; font-weight: bold');
      console.log(`%câ•‘   Average: ${avgTotal.toFixed(2)}ms`, 'color: #4ade80');
      console.log('%câ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•', 'color: #22c55e');
      
      return {
        requests: state.successCount + state.failCount,
        success: state.successCount,
        failed: state.failCount,
        mrProcessing: { avg: avgMR, min: minMR, max: maxMR },
        provider: { avg: avgProv, min: minProv, max: maxProv },
        total: { avg: avgTotal },
        raw: { mrProcessing: state.mrProcessingTimes, provider: state.providerTimes, total: state.totalTimes }
      };
    };
    
    console.log('%c[MemoryRouter Test Page]', 'color: #22c55e; font-weight: bold', 
      'Latency logging enabled. Call dumpLatencyStats() for summary.');

    // ========================
    // Init
    // ========================
    loadConfig();
    messageInput.focus();
  </script>
</body>
</html>
<!-- deployed Sun Feb  1 14:30:57 EST 2026 -->
<!-- cache-bust: 1769974451 -->
